# ğŸ’® Araliya Tiny-byLLM Plugin

Seamlessly integrates byllm calls with TinyLlama through a local tiny-server, supporting fine-tuning and evaluationÂ workflows.

---

## ğŸš€ Quick Start


### ğŸ”§Tiny-byLLM(Plugin)

**Installation**
```bash
cd tiny-byllm/
pip install -e .
```

### ğŸ–¥ï¸ Run Tiny Server

**Install dependencies:**

```bash
pip install fastapi "uvicorn[standard]" accelerate outlines transformers peft datasets
```

**Run the server:**

```bash
cd tiny-server/
uvicorn app:app --host 0.0.0.0 --port 7000
```
---

## âœ¨ Features

ğŸ”Œ Seamless Jac integration

ğŸ§  TinyLlama 1.1B backbone

ğŸ”„ Intelligent training & evaluation process

ğŸŒ Independent OpenAI APIâ€“compatible tiny-server

ğŸ› Hot-swappable LoRA adapters (as for multitask usage â€” to be added)

   
---

## ğŸ”§ Compatibility

âœ… Updated to work with byllm

ğŸ—‚ Use the mtllm-compatible branch for mtllmÂ (deprecated)
